---
phase: 13-external-api-mocks
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/conftest.py
  - tests/fixtures/__init__.py
  - tests/fixtures/bigquery_fixtures.py
  - tests/test_analytics_routes.py
autonomous: true

must_haves:
  truths:
    - "BigQuery client can be mocked with realistic query responses"
    - "Analytics routes tests achieve 50%+ coverage (up from 9.4%)"
    - "Mock fixtures are reusable across test files"
  artifacts:
    - path: "tests/fixtures/bigquery_fixtures.py"
      provides: "Reusable BigQuery mock factory and realistic data generators"
      min_lines: 100
    - path: "tests/conftest.py"
      provides: "Shared pytest fixtures including BigQuery mocks"
      contains: "mock_bigquery_client"
  key_links:
    - from: "tests/test_analytics_routes.py"
      to: "tests/fixtures/bigquery_fixtures.py"
      via: "pytest fixture import"
      pattern: "from tests.fixtures.bigquery_fixtures import"
    - from: "tests/test_analytics_routes.py"
      to: "src/api/analytics_routes.py"
      via: "FastAPI TestClient with mocked dependencies"
      pattern: "client\\.get.*analytics"
---

<objective>
Create reusable BigQuery mock infrastructure and expand analytics route tests to achieve 50%+ coverage.

Purpose: The analytics routes currently have only 9.4% coverage because they depend on BigQuery queries that cannot be tested without mocking. This plan creates a reusable mock infrastructure that simulates BigQuery responses, enabling comprehensive testing of dashboard stats, quote analytics, invoice analytics, call analytics, and pipeline analytics endpoints.

Output:
- tests/fixtures/bigquery_fixtures.py with mock factory and data generators
- Enhanced tests/test_analytics_routes.py with 50%+ coverage
- Shared fixtures in tests/conftest.py for cross-file reuse
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/api/analytics_routes.py
@tests/test_analytics_routes.py
@tests/test_bigquery_tool.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create BigQuery mock fixtures module</name>
  <files>
    tests/fixtures/__init__.py
    tests/fixtures/bigquery_fixtures.py
  </files>
  <action>
Create tests/fixtures/ directory and bigquery_fixtures.py with:

1. **MockBigQueryRow class** - Simulates BigQuery row objects with attribute access:
   - Takes dict and provides attribute access (row.hotel_name, row.total_price)
   - Supports iteration for query results

2. **MockBigQueryQueryJob class** - Simulates query job:
   - `.result(timeout=N)` returns iterator of MockBigQueryRow
   - Tracks call count for verification

3. **MockBigQueryClient class** - Full client mock:
   - `.query(sql, job_config=...)` returns MockBigQueryQueryJob
   - Captures executed queries for assertions
   - Configurable response data per query pattern

4. **Data generators** - Factory functions for realistic test data:
   - `generate_hotel_rates(n=5)` - Hotel rate records with realistic values
   - `generate_quotes(n=3, statuses=['accepted', 'sent', 'draft'])` - Quote data
   - `generate_invoices(n=3)` - Invoice data with due dates and amounts
   - `generate_call_records(n=5)` - Call records with outcomes/durations
   - `generate_dashboard_stats()` - Pre-aggregated dashboard metrics

5. **Fixture factory function**:
   - `create_mock_bigquery_client(default_data=None)` - Returns configured mock
   - Supports query pattern matching to return different data for different queries

Example usage pattern:
```python
from tests.fixtures.bigquery_fixtures import create_mock_bigquery_client, generate_hotel_rates

mock_client = create_mock_bigquery_client()
mock_client.set_response_for_pattern("hotel_rates", generate_hotel_rates(5))
```
  </action>
  <verify>
Run `python -c "from tests.fixtures.bigquery_fixtures import create_mock_bigquery_client, generate_quotes; print('Import successful')"` to verify module loads without errors.
  </verify>
  <done>
BigQuery mock fixtures module exists at tests/fixtures/bigquery_fixtures.py with MockBigQueryClient class, data generators, and factory function.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add shared fixtures to conftest.py</name>
  <files>tests/conftest.py</files>
  <action>
Update tests/conftest.py to add shared fixtures that can be used across multiple test files:

1. **mock_bigquery_client fixture** (session-scoped):
   ```python
   @pytest.fixture
   def mock_bigquery_client():
       from tests.fixtures.bigquery_fixtures import create_mock_bigquery_client
       return create_mock_bigquery_client()
   ```

2. **mock_supabase_for_analytics fixture**:
   - Create chainable mock for Supabase queries used in analytics routes
   - Pattern: `mock.client.table('quotes').select(...).eq(...).execute()` returns mock data
   - Support for `.gte()`, `.order()`, `.limit()` method chaining

3. **mock_crm_service fixture**:
   - Mock CRMService.get_pipeline_summary() and get_client_stats()
   - Return realistic pipeline stage data

4. **authenticated_client fixture**:
   - TestClient with mocked auth middleware
   - Bypasses JWT validation for analytics route testing
   - Sets X-Client-ID header to 'test_tenant'

These fixtures should patch at the module level where dependencies are imported:
- `src.api.analytics_routes.SupabaseTool`
- `src.api.analytics_routes.CRMService`
- `src.api.analytics_routes.get_bigquery_client_async`
  </action>
  <verify>
Run `pytest tests/test_analytics_routes.py::TestHelperFunctions -v` to verify conftest.py loads without breaking existing tests.
  </verify>
  <done>
conftest.py contains mock_bigquery_client, mock_supabase_for_analytics, mock_crm_service, and authenticated_client fixtures that can be imported by any test file.
  </done>
</task>

<task type="auto">
  <name>Task 3: Expand analytics routes test coverage to 50%+</name>
  <files>tests/test_analytics_routes.py</files>
  <action>
Expand test_analytics_routes.py with comprehensive endpoint tests using the new mock infrastructure:

1. **TestDashboardStatsWithMocks** class:
   - `test_dashboard_stats_returns_quote_metrics` - Mock supabase quotes table, verify counts/conversion
   - `test_dashboard_stats_returns_revenue_metrics` - Mock invoices, verify collected/outstanding/overdue
   - `test_dashboard_stats_returns_client_metrics` - Mock clients, verify total/new/active
   - `test_dashboard_stats_returns_call_metrics` - Mock call_records, verify completed/pending
   - `test_dashboard_stats_handles_empty_data` - All tables return empty, verify zero counts
   - `test_dashboard_stats_handles_supabase_error` - Mock raises exception, verify graceful degradation

2. **TestDashboardActivityWithMocks** class:
   - `test_recent_activity_returns_quotes` - Mock recent quotes, verify activity items
   - `test_recent_activity_returns_invoices` - Mock recent invoices
   - `test_recent_activity_sorts_by_timestamp` - Multiple types, verify sorted output
   - `test_recent_activity_respects_limit` - Request limit=5, verify 5 items returned

3. **TestDashboardAllWithMocks** class (aggregated endpoint):
   - `test_dashboard_all_returns_stats` - Mock all data sources, verify stats object
   - `test_dashboard_all_returns_recent_quotes` - Verify recent_quotes array
   - `test_dashboard_all_returns_usage` - Verify usage limits object
   - `test_dashboard_all_caches_result` - Call twice, verify cache hit (cached=True)
   - `test_dashboard_all_handles_bigquery_unavailable` - Mock BQ client None, verify 0 for hotels/destinations

4. **TestQuoteAnalyticsWithMocks** class:
   - `test_quote_analytics_summary` - Mock quotes, verify total/total_value/avg_value/conversion_rate
   - `test_quote_analytics_by_status` - Mock mixed statuses, verify by_status breakdown
   - `test_quote_analytics_by_destination` - Mock destinations, verify by_destination list
   - `test_quote_analytics_by_hotel` - Mock quotes with hotels JSON, verify by_hotel list
   - `test_quote_analytics_trend` - Mock dates spanning period, verify trend data

5. **TestInvoiceAnalyticsWithMocks** class:
   - `test_invoice_analytics_summary` - Mock invoices, verify totals
   - `test_invoice_analytics_aging` - Mock overdue invoices, verify aging buckets (30_days, 60_days, 90_plus_days)
   - `test_invoice_analytics_payment_rate` - Mock paid/unpaid, verify payment_rate calculation

6. **TestCallAnalyticsWithMocks** class:
   - `test_call_analytics_summary` - Mock call_records, verify total/completed/failed/success_rate
   - `test_call_analytics_queue` - Mock outbound_call_queue, verify pending/scheduled/in_progress
   - `test_call_analytics_by_outcome` - Verify by_outcome breakdown

7. **TestPipelineAnalyticsWithMocks** class:
   - `test_pipeline_analytics_funnel` - Mock CRMService, verify funnel conversion rates
   - `test_pipeline_analytics_by_source` - Verify by_source breakdown

Mock patterns to use:
```python
@patch('src.api.analytics_routes.SupabaseTool')
@patch('src.api.analytics_routes.get_client_config')
def test_example(self, mock_get_config, mock_supabase_class):
    mock_config = MagicMock()
    mock_config.client_id = 'test_tenant'
    mock_get_config.return_value = mock_config

    mock_supabase = MagicMock()
    mock_supabase.client.table.return_value.select.return_value.eq.return_value.gte.return_value.execute.return_value = MagicMock(data=[...])
    mock_supabase_class.return_value = mock_supabase
```
  </action>
  <verify>
Run `pytest tests/test_analytics_routes.py -v --cov=src/api/analytics_routes --cov-report=term-missing` and verify coverage is at least 50%.
  </verify>
  <done>
test_analytics_routes.py has 25+ new tests covering all analytics endpoints with mocked dependencies, achieving 50%+ coverage on src/api/analytics_routes.py.
  </done>
</task>

</tasks>

<verification>
1. Run full analytics test suite: `pytest tests/test_analytics_routes.py -v`
2. Check coverage: `pytest tests/test_analytics_routes.py --cov=src/api/analytics_routes --cov-report=term-missing`
3. Verify coverage threshold: Coverage should be >= 50% (up from 9.4%)
4. Verify fixtures are reusable: `python -c "from tests.fixtures.bigquery_fixtures import *; print('Fixtures importable')"`
</verification>

<success_criteria>
- All new tests pass
- Analytics routes coverage >= 50% (measured by pytest-cov)
- BigQuery mock fixtures are reusable (importable from tests/fixtures/)
- No regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/13-external-api-mocks/13-01-SUMMARY.md`
</output>
