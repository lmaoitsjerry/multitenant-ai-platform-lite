---
phase: 16-critical-fixes
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/api/routes.py
  - src/services/faiss_helpdesk_service.py
autonomous: true

must_haves:
  truths:
    - "DI caching is thread-safe under concurrent requests"
    - "FAISS singleton initializes only once even under concurrent access"
    - "No race conditions when multiple workers start simultaneously"
  artifacts:
    - path: "src/api/routes.py"
      provides: "Thread-safe DI caching with functools.lru_cache"
      contains: "@lru_cache"
    - path: "src/services/faiss_helpdesk_service.py"
      provides: "Thread-safe singleton with double-check locking"
      contains: "threading.Lock"
  key_links:
    - from: "src/api/routes.py"
      to: "functools.lru_cache"
      via: "decorator on get_client_config"
      pattern: "@lru_cache.*def get_client_config"
    - from: "src/services/faiss_helpdesk_service.py"
      to: "threading.Lock"
      via: "class-level lock for singleton"
      pattern: "_lock.*Lock"
---

<objective>
Fix thread-safety issues in DI caching and FAISS singleton initialization.

Purpose: Prevent race conditions that could cause duplicate service initialization, memory leaks, or inconsistent state under concurrent load.

Output: Thread-safe caching using Python standard library patterns (lru_cache, threading.Lock).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/PRODUCTION-AUDIT.md
@src/api/routes.py (lines 129-171)
@src/services/faiss_helpdesk_service.py (lines 34-60)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace dict-based DI caching with thread-safe lru_cache</name>
  <files>src/api/routes.py</files>
  <action>
Replace the global dict caching pattern (lines 131-170) with `functools.lru_cache`:

1. Remove the global dicts at lines 132-134:
   ```python
   # DELETE THESE:
   _client_configs = {}
   _quote_agents = {}
   _crm_services = {}
   ```

2. Replace `get_client_config` function with lru_cache version:
   ```python
   from functools import lru_cache

   @lru_cache(maxsize=100)
   def _get_cached_config(client_id: str) -> ClientConfig:
       """Get cached client configuration - thread-safe via lru_cache"""
       return ClientConfig(client_id)

   def get_client_config(x_client_id: str = Header(None, alias="X-Client-ID")) -> ClientConfig:
       """Get client configuration from header"""
       import os
       client_id = x_client_id or os.getenv("CLIENT_ID", "example")

       try:
           config = _get_cached_config(client_id)
           logger.info(f"Loaded configuration for client: {client_id}")
           return config
       except Exception as e:
           logger.error(f"Failed to load config for {client_id}: {e}")
           raise HTTPException(status_code=400, detail=f"Invalid client: {client_id}")
   ```

3. Replace `get_quote_agent` with lru_cache version:
   ```python
   @lru_cache(maxsize=100)
   def _get_cached_quote_agent(client_id: str):
       """Get cached QuoteAgent - thread-safe via lru_cache"""
       from src.agents.quote_agent import QuoteAgent
       config = _get_cached_config(client_id)
       return QuoteAgent(config)

   def get_quote_agent(config: ClientConfig):
       """Get cached QuoteAgent for client"""
       return _get_cached_quote_agent(config.client_id)
   ```

4. Replace `get_crm_service` with lru_cache version:
   ```python
   @lru_cache(maxsize=100)
   def _get_cached_crm_service(client_id: str):
       """Get cached CRMService - thread-safe via lru_cache"""
       config = _get_cached_config(client_id)
       return CRMService(config)

   def get_crm_service(config: ClientConfig):
       """Get cached CRMService for client"""
       return _get_cached_crm_service(config.client_id)
   ```

NOTE: Use `lru_cache` from functools, not `cache` (which is unbounded). The maxsize=100 limits memory usage while allowing caching for the expected number of tenants.
  </action>
  <verify>
Run: `python -c "from src.api.routes import get_client_config, get_quote_agent, get_crm_service; print('Imports successful')"` should pass without errors.
  </verify>
  <done>DI caching uses functools.lru_cache instead of plain dicts, providing thread-safety via GIL-protected atomic operations.</done>
</task>

<task type="auto">
  <name>Task 2: Add double-check locking to FAISS singleton</name>
  <files>src/services/faiss_helpdesk_service.py</files>
  <action>
Fix the race condition in the FAISS singleton pattern (lines 42-49):

1. Add threading import and class-level lock at the top of the class:
   ```python
   import threading

   class FAISSHelpdeskService:
       """
       Service to query the shared FAISS helpdesk index from Google Cloud Storage.

       The index is downloaded once and cached locally for performance.
       Uses the same embeddings model that was used to create the index.
       Thread-safe singleton pattern with double-check locking.
       """

       _instance = None
       _lock = threading.Lock()
   ```

2. Replace the `__new__` method with double-check locking pattern:
   ```python
   def __new__(cls):
       """Singleton pattern with double-check locking for thread safety"""
       if cls._instance is None:
           with cls._lock:
               # Double-check inside lock to prevent race condition
               if cls._instance is None:
                   cls._instance = super().__new__(cls)
                   cls._instance._initialized = False
       return cls._instance
   ```

The double-check pattern:
- First check (outside lock): Fast path for already-initialized case
- Lock acquisition: Only one thread can proceed
- Second check (inside lock): Ensures only one initialization even if multiple threads passed the first check

This prevents the race condition where multiple threads could simultaneously see `_instance is None` and both try to create instances.
  </action>
  <verify>
Run: `python -c "import threading; from src.services.faiss_helpdesk_service import FAISSHelpdeskService; instances = []; def create(): instances.append(FAISSHelpdeskService()); threads = [threading.Thread(target=create) for _ in range(10)]; [t.start() for t in threads]; [t.join() for t in threads]; print(f'Created {len(instances)} instances, all same: {all(i is instances[0] for i in instances)}')"` should output "all same: True".
  </verify>
  <done>FAISS singleton uses double-check locking pattern, preventing race conditions during initialization.</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for thread-safety</name>
  <files>tests/test_thread_safety.py</files>
  <action>
Create a new test file to verify thread-safety of the fixed patterns:

```python
"""Thread safety tests for DI caching and FAISS singleton."""
import threading
import time
import pytest
from unittest.mock import patch, MagicMock


class TestDICachingThreadSafety:
    """Tests for thread-safe DI caching in routes.py"""

    def test_lru_cache_returns_same_config(self):
        """Verify lru_cache returns same instance for same client_id"""
        from src.api.routes import _get_cached_config

        # Clear cache first
        _get_cached_config.cache_clear()

        with patch('src.config.loader.ClientConfig') as mock_config:
            mock_config.return_value = MagicMock(client_id='test-tenant')

            config1 = _get_cached_config('test-tenant')
            config2 = _get_cached_config('test-tenant')

            # Same instance returned
            assert config1 is config2
            # Constructor called only once
            assert mock_config.call_count == 1

    def test_concurrent_config_access(self):
        """Verify no race condition under concurrent access"""
        from src.api.routes import _get_cached_config

        _get_cached_config.cache_clear()

        results = []
        errors = []

        with patch('src.config.loader.ClientConfig') as mock_config:
            mock_config.return_value = MagicMock(client_id='concurrent-tenant')

            def get_config():
                try:
                    config = _get_cached_config('concurrent-tenant')
                    results.append(config)
                except Exception as e:
                    errors.append(e)

            # Launch 20 concurrent threads
            threads = [threading.Thread(target=get_config) for _ in range(20)]
            for t in threads:
                t.start()
            for t in threads:
                t.join()

            assert len(errors) == 0, f"Errors occurred: {errors}"
            assert len(results) == 20
            # All results should be the same instance
            assert all(r is results[0] for r in results)


class TestFAISSSingletonThreadSafety:
    """Tests for thread-safe FAISS singleton"""

    def test_singleton_returns_same_instance(self):
        """Verify singleton returns same instance"""
        from src.services.faiss_helpdesk_service import FAISSHelpdeskService

        # Reset singleton for test
        FAISSHelpdeskService._instance = None

        service1 = FAISSHelpdeskService()
        service2 = FAISSHelpdeskService()

        assert service1 is service2

    def test_concurrent_singleton_creation(self):
        """Verify only one instance created under concurrent access"""
        from src.services.faiss_helpdesk_service import FAISSHelpdeskService

        # Reset singleton for test
        FAISSHelpdeskService._instance = None

        instances = []
        errors = []

        def create_instance():
            try:
                instance = FAISSHelpdeskService()
                instances.append(instance)
            except Exception as e:
                errors.append(e)

        # Launch 20 concurrent threads
        threads = [threading.Thread(target=create_instance) for _ in range(20)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

        assert len(errors) == 0, f"Errors occurred: {errors}"
        assert len(instances) == 20
        # All instances should be the same object
        assert all(i is instances[0] for i in instances)

    def test_double_check_locking_exists(self):
        """Verify the class has proper locking mechanism"""
        from src.services.faiss_helpdesk_service import FAISSHelpdeskService

        # Verify _lock exists and is a Lock
        assert hasattr(FAISSHelpdeskService, '_lock')
        assert isinstance(FAISSHelpdeskService._lock, type(threading.Lock()))
```
  </action>
  <verify>
Run: `pytest tests/test_thread_safety.py -v` should pass all 5 tests.
  </verify>
  <done>Unit tests verify thread-safety of DI caching and FAISS singleton under concurrent access.</done>
</task>

</tasks>

<verification>
1. All existing tests pass: `pytest tests/ -x --ignore=tests/test_thread_safety.py`
2. New thread-safety tests pass: `pytest tests/test_thread_safety.py -v`
3. Application starts without errors: `python -c "from src.api.routes import api_router; print('Routes imported successfully')"`
</verification>

<success_criteria>
- DI caching functions use `@lru_cache` decorator
- FAISS singleton uses `threading.Lock` with double-check pattern
- No `_client_configs`, `_quote_agents`, `_crm_services` global dicts remain
- Thread-safety tests pass with 20 concurrent threads
- Existing test suite passes (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/16-critical-fixes/16-01-SUMMARY.md`
</output>
