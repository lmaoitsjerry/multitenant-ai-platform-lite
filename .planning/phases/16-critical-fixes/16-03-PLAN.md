---
phase: 16-critical-fixes
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/crm_service.py
  - database/migrations/015_production_indexes.sql
  - tests/test_crm_service.py
autonomous: true
user_setup:
  - service: supabase
    why: "Apply database migration for new indexes"
    dashboard_config:
      - task: "Run migration 015_production_indexes.sql"
        location: "Supabase Dashboard -> SQL Editor -> New query -> Paste and run"

must_haves:
  truths:
    - "CRM search executes maximum 3 queries (clients + batch quotes + batch activities)"
    - "Database indexes exist for tenant_id + email and tenant_id + client_id patterns"
    - "Search performance improves with batch queries vs N+1"
  artifacts:
    - path: "src/services/crm_service.py"
      provides: "Batch query implementation for search_clients enrichment"
      contains: "in_"
    - path: "database/migrations/015_production_indexes.sql"
      provides: "Composite indexes for common query patterns"
      contains: "idx_quotes_tenant_email"
    - path: "tests/test_crm_service.py"
      provides: "Tests verifying batch query behavior"
      contains: "test_search_clients_batch"
  key_links:
    - from: "src/services/crm_service.py"
      to: "supabase.client.table('quotes')"
      via: "single batch query with in_ filter"
      pattern: "\.in_\\("
---

<objective>
Fix N+1 query performance issue in CRM search and add missing database indexes.

Purpose: Reduce CRM search latency from O(n) queries to O(1) by batching enrichment queries, and optimize common query patterns with database indexes.

Output: Batch query implementation in crm_service.py and new database migration with production indexes.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/PRODUCTION-AUDIT.md
@src/services/crm_service.py (lines 250-340)
@database/migrations/004_performance_indexes.sql
@database/migrations/006_additional_performance_indexes.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace N+1 queries with batch queries in search_clients</name>
  <files>src/services/crm_service.py</files>
  <action>
Refactor the `search_clients` method (lines 250-340) to use batch queries instead of per-client queries:

Replace the enrichment loop (lines 288-334) with batch queries:

```python
def search_clients(
    self,
    query: Optional[str] = None,
    stage: Optional[PipelineStage] = None,
    consultant_id: Optional[str] = None,
    limit: int = 50,
    offset: int = 0
) -> List[Dict[str, Any]]:
    """Search and list clients with enriched data using batch queries"""
    if not self.supabase or not self.supabase.client:
        return []

    try:
        q = self.supabase.client.table('clients')\
            .select("*")\
            .eq('tenant_id', self.config.client_id)\
            .order('created_at', desc=True)\
            .range(offset, offset + limit - 1)

        if stage:
            q = q.eq('pipeline_stage', stage.value)

        if consultant_id:
            q = q.eq('consultant_id', consultant_id)

        result = q.execute()
        clients = result.data or []

        # Filter by query if provided (client-side for now)
        if query:
            query_lower = query.lower()
            clients = [
                c for c in clients
                if query_lower in c.get('name', '').lower()
                or query_lower in c.get('email', '').lower()
                or query_lower in (c.get('phone') or '').lower()
            ]

        if not clients:
            return []

        # Collect emails and client_ids for batch queries
        client_emails = [c.get('email') for c in clients if c.get('email')]
        client_ids = [c.get('client_id') for c in clients if c.get('client_id')]

        # Batch query 1: Get latest quotes for all clients in one query
        quotes_by_email = {}
        if client_emails:
            try:
                quotes_result = self.supabase.client.table('quotes')\
                    .select("customer_email, destination, total_price, created_at")\
                    .eq('tenant_id', self.config.client_id)\
                    .in_('customer_email', client_emails)\
                    .order('created_at', desc=True)\
                    .execute()

                # Group by email, keeping only the latest (first due to order)
                for quote in (quotes_result.data or []):
                    email = quote.get('customer_email')
                    if email and email not in quotes_by_email:
                        quotes_by_email[email] = quote
            except Exception as e:
                logger.debug(f"Could not batch fetch quotes: {e}")

        # Batch query 2: Get latest activities for all clients in one query
        activities_by_client = {}
        if client_ids:
            try:
                activities_result = self.supabase.client.table('activities')\
                    .select("client_id, created_at")\
                    .eq('tenant_id', self.config.client_id)\
                    .in_('client_id', client_ids)\
                    .order('created_at', desc=True)\
                    .execute()

                # Group by client_id, keeping only the latest (first due to order)
                for activity in (activities_result.data or []):
                    cid = activity.get('client_id')
                    if cid and cid not in activities_by_client:
                        activities_by_client[cid] = activity
            except Exception as e:
                logger.debug(f"Could not batch fetch activities: {e}")

        # Enrich clients with batch query results
        enriched_clients = []
        for client in clients:
            enriched = {**client}

            # Map total_value to value for frontend
            enriched['value'] = client.get('total_value', 0)

            # Get latest quote from batch result
            email = client.get('email')
            if email and email in quotes_by_email:
                latest_quote = quotes_by_email[email]
                enriched['destination'] = latest_quote.get('destination')
                if latest_quote.get('total_price'):
                    enriched['value'] = latest_quote.get('total_price')

            # Get last activity from batch result
            client_id = client.get('client_id')
            if client_id and client_id in activities_by_client:
                enriched['last_activity'] = activities_by_client[client_id].get('created_at')
            else:
                enriched['last_activity'] = client.get('updated_at')

            enriched_clients.append(enriched)

        return enriched_clients

    except Exception as e:
        logger.error(f"Failed to search clients: {e}")
        return []
```

This reduces the query count from 1 + 2*N (where N is number of clients) to a maximum of 3 queries:
1. Get clients
2. Get all quotes for those clients (batch)
3. Get all activities for those clients (batch)
  </action>
  <verify>
Run: `python -c "from src.services.crm_service import CRMService; print('Import successful')"` should pass.
  </verify>
  <done>CRM search_clients uses batch queries, reducing N+1 to maximum 3 queries.</done>
</task>

<task type="auto">
  <name>Task 2: Create database migration for production indexes</name>
  <files>database/migrations/015_production_indexes.sql</files>
  <action>
Create a new migration file with indexes optimized for the batch query patterns:

```sql
-- Migration: Production Performance Indexes
-- Date: 2026-01-23
-- Phase: 16 - Critical Fixes
-- Description: Adds composite indexes for CRM batch queries and common production patterns

-- =====================================================
-- QUOTES TABLE INDEXES (for CRM batch enrichment)
-- =====================================================

-- Composite index for batch quote lookup by tenant + customer_email
-- Used by CRM search_clients batch query
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_quotes_tenant_customer_email
    ON quotes(tenant_id, customer_email, created_at DESC);

-- =====================================================
-- ACTIVITIES TABLE INDEXES (for CRM batch enrichment)
-- =====================================================

-- Composite index for batch activity lookup by tenant + client_id
-- Used by CRM search_clients batch query
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_activities_tenant_client_created
    ON activities(tenant_id, client_id, created_at DESC);

-- =====================================================
-- CLIENTS TABLE INDEXES (for CRM search)
-- =====================================================

-- Composite index for client email lookup (used in CRM deduplication)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_clients_tenant_email
    ON clients(tenant_id, email);

-- =====================================================
-- INVOICES TABLE INDEXES (additional for reporting)
-- =====================================================

-- Composite index for invoice lookup by tenant + status + date
-- Used by financial reports
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_invoices_tenant_status_created
    ON invoices(tenant_id, status, created_at DESC);

-- =====================================================
-- VERIFICATION
-- =====================================================
-- Run this to verify indexes were created:
/*
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_indexes
WHERE indexname IN (
    'idx_quotes_tenant_customer_email',
    'idx_activities_tenant_client_created',
    'idx_clients_tenant_email',
    'idx_invoices_tenant_status_created'
)
ORDER BY tablename, indexname;
*/

-- Update statistics for query planner
ANALYZE quotes;
ANALYZE activities;
ANALYZE clients;
ANALYZE invoices;
```

NOTE: Uses CONCURRENTLY to avoid locking tables during index creation (allows reads/writes during indexing).
  </action>
  <verify>
Verify SQL syntax: `cat database/migrations/015_production_indexes.sql | head -30` should show valid SQL.
  </verify>
  <done>Database migration 015_production_indexes.sql created with composite indexes for batch query patterns.</done>
</task>

<task type="auto">
  <name>Task 3: Add tests verifying batch query behavior</name>
  <files>tests/test_crm_service.py</files>
  <action>
Add tests to verify the batch query implementation. First read the existing test file structure, then add:

```python
class TestCRMServiceBatchQueries:
    """Tests for batch query optimization in CRM service"""

    @pytest.fixture
    def mock_supabase_client(self):
        """Create a mock Supabase client for testing"""
        mock_client = MagicMock()
        return mock_client

    def test_search_clients_uses_batch_queries(self, mock_supabase_client):
        """Verify search_clients uses batch queries instead of N+1"""
        from src.services.crm_service import CRMService
        from unittest.mock import patch, MagicMock

        # Mock config
        mock_config = MagicMock()
        mock_config.client_id = 'test-tenant'

        # Create service with mocked Supabase
        service = CRMService(mock_config)
        service.supabase = MagicMock()
        service.supabase.client = mock_supabase_client

        # Setup mock responses
        clients_data = [
            {'client_id': 'cli-1', 'email': 'a@test.com', 'name': 'A', 'total_value': 100},
            {'client_id': 'cli-2', 'email': 'b@test.com', 'name': 'B', 'total_value': 200},
            {'client_id': 'cli-3', 'email': 'c@test.com', 'name': 'C', 'total_value': 300},
        ]

        quotes_data = [
            {'customer_email': 'a@test.com', 'destination': 'Paris', 'total_price': 1500, 'created_at': '2024-01-01'},
            {'customer_email': 'b@test.com', 'destination': 'Rome', 'total_price': 2000, 'created_at': '2024-01-02'},
        ]

        activities_data = [
            {'client_id': 'cli-1', 'created_at': '2024-01-15'},
            {'client_id': 'cli-2', 'created_at': '2024-01-16'},
        ]

        # Mock the chain of method calls
        mock_table = MagicMock()
        mock_select = MagicMock()
        mock_eq = MagicMock()
        mock_order = MagicMock()
        mock_range = MagicMock()
        mock_in = MagicMock()

        def table_handler(table_name):
            table_mock = MagicMock()

            if table_name == 'clients':
                table_mock.select.return_value.eq.return_value.order.return_value.range.return_value.execute.return_value.data = clients_data
            elif table_name == 'quotes':
                table_mock.select.return_value.eq.return_value.in_.return_value.order.return_value.execute.return_value.data = quotes_data
            elif table_name == 'activities':
                table_mock.select.return_value.eq.return_value.in_.return_value.order.return_value.execute.return_value.data = activities_data

            return table_mock

        mock_supabase_client.table = table_handler

        # Execute search
        results = service.search_clients()

        # Verify we got enriched results
        assert len(results) == 3

        # Verify client A got quote enrichment
        client_a = next(r for r in results if r['client_id'] == 'cli-1')
        assert client_a['destination'] == 'Paris'
        assert client_a['value'] == 1500
        assert client_a['last_activity'] == '2024-01-15'

        # Verify client C has no quote but has fallback values
        client_c = next(r for r in results if r['client_id'] == 'cli-3')
        assert client_c['value'] == 300  # Original total_value

    def test_search_clients_handles_empty_results(self, mock_supabase_client):
        """Verify search handles empty client list without errors"""
        from src.services.crm_service import CRMService
        from unittest.mock import MagicMock

        mock_config = MagicMock()
        mock_config.client_id = 'test-tenant'

        service = CRMService(mock_config)
        service.supabase = MagicMock()
        service.supabase.client = mock_supabase_client

        # Return empty clients
        mock_supabase_client.table.return_value.select.return_value.eq.return_value.order.return_value.range.return_value.execute.return_value.data = []

        results = service.search_clients()

        assert results == []

    def test_search_clients_query_count(self, mock_supabase_client):
        """Verify maximum 3 queries are executed (clients + quotes + activities)"""
        from src.services.crm_service import CRMService
        from unittest.mock import MagicMock, call

        mock_config = MagicMock()
        mock_config.client_id = 'test-tenant'

        service = CRMService(mock_config)
        service.supabase = MagicMock()
        service.supabase.client = mock_supabase_client

        # Track table() calls
        table_calls = []
        original_table = MagicMock()

        def track_table(table_name):
            table_calls.append(table_name)
            mock = MagicMock()
            if table_name == 'clients':
                mock.select.return_value.eq.return_value.order.return_value.range.return_value.execute.return_value.data = [
                    {'client_id': 'cli-1', 'email': 'a@test.com', 'name': 'A'}
                ]
            else:
                mock.select.return_value.eq.return_value.in_.return_value.order.return_value.execute.return_value.data = []
            return mock

        mock_supabase_client.table = track_table

        service.search_clients()

        # Should be exactly 3 table() calls: clients, quotes, activities
        assert len(table_calls) == 3
        assert table_calls[0] == 'clients'
        assert 'quotes' in table_calls
        assert 'activities' in table_calls
```
  </action>
  <verify>
Run: `pytest tests/test_crm_service.py -v -k "batch"` should pass the new batch query tests.
  </verify>
  <done>Tests verify batch query implementation uses maximum 3 queries instead of N+1.</done>
</task>

</tasks>

<verification>
1. Existing CRM tests pass: `pytest tests/test_crm_service.py -v`
2. New batch query tests pass: `pytest tests/test_crm_service.py -v -k "batch"`
3. SQL migration has valid syntax: File exists at database/migrations/015_production_indexes.sql
4. No N+1 pattern in code: `grep -n "for client in clients" src/services/crm_service.py` should show only the final enrichment loop (no nested queries)
</verification>

<success_criteria>
- search_clients method uses `in_()` for batch queries
- Maximum 3 database queries per search (clients + quotes + activities)
- New migration file 015_production_indexes.sql exists
- Migration includes idx_quotes_tenant_customer_email index
- Migration includes idx_activities_tenant_client_created index
- Batch query tests pass
- Existing CRM tests still pass

NOTE: User must run the migration manually:
```
1. Open Supabase Dashboard
2. Go to SQL Editor
3. Create new query
4. Paste contents of database/migrations/015_production_indexes.sql
5. Run the query
```
</success_criteria>

<output>
After completion, create `.planning/phases/16-critical-fixes/16-03-SUMMARY.md`
</output>
