---
phase: 15-coverage-finalization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/fixtures/gcs_fixtures.py
  - tests/test_rag_tool.py
  - tests/test_faiss_service.py
  - tests/test_file_upload.py
autonomous: true

must_haves:
  truths:
    - "RAG tool can search knowledge base without real Vertex AI"
    - "FAISS service can be tested without GCS connection"
    - "Vector operations are mocked for deterministic testing"
    - "File upload tests cover multipart handling"
  artifacts:
    - path: "tests/fixtures/gcs_fixtures.py"
      provides: "Reusable GCS and FAISS mock infrastructure"
      exports: ["MockGCSClient", "MockFAISSIndex", "create_mock_faiss_service"]
    - path: "tests/test_rag_tool.py"
      provides: "RAG tool test coverage"
      min_lines: 150
    - path: "tests/test_faiss_service.py"
      provides: "FAISS helpdesk service test coverage"
      min_lines: 200
    - path: "tests/test_file_upload.py"
      provides: "File upload multipart handling tests"
      min_lines: 100
  key_links:
    - from: "tests/test_rag_tool.py"
      to: "src/tools/rag_tool.py"
      via: "import and mock Vertex AI"
      pattern: "patch.*vertexai"
    - from: "tests/test_faiss_service.py"
      to: "src/services/faiss_helpdesk_service.py"
      via: "import and mock GCS/FAISS"
      pattern: "patch.*google.cloud.storage"
---

<objective>
Create mock infrastructure and comprehensive tests for RAG tool and FAISS helpdesk service.

Purpose: Enable testing of vector search operations without real Vertex AI or GCS connections. The rag_tool.py uses Vertex AI RAG corpus while faiss_helpdesk_service.py downloads index from GCS - both need mocked dependencies for isolated testing.

Output: GCS/FAISS mock fixtures + RAG tool tests + FAISS service tests achieving 50%+ coverage on both modules
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@tests/fixtures/bigquery_fixtures.py (pattern reference)
@tests/fixtures/openai_fixtures.py (pattern reference)
@src/tools/rag_tool.py (module to test)
@src/services/faiss_helpdesk_service.py (module to test)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GCS and FAISS mock infrastructure</name>
  <files>tests/fixtures/gcs_fixtures.py</files>
  <action>
Create reusable mock classes for Google Cloud Storage and FAISS following existing fixture patterns:

1. **MockGCSBlob** class:
   - Attributes: `name`, `size`, `metadata`, `time_created`, `updated`
   - Methods: `exists()`, `download_to_filename()`, `download_as_text()`, `upload_from_string()`

2. **MockGCSBucket** class:
   - Attributes: `name`
   - Methods: `blob(name)`, `list_blobs(prefix)`
   - Configurable to return predetermined blobs

3. **MockGCSClient** class:
   - Methods: `bucket(name)` - returns MockGCSBucket
   - Track method calls for assertions

4. **MockFAISSIndex** class:
   - Attributes: `ntotal` (number of vectors)
   - Methods: `search(query_vector, k)` - returns (distances, indices)
   - Configurable to return predetermined search results

5. **MockDocstore** class:
   - Simulates LangChain InMemoryDocstore
   - Methods: `search(doc_id)` - returns document or None

6. **MockSentenceTransformer** class:
   - Methods: `embed_query(text)` - returns 768-dim float list
   - Methods: `embed_documents(texts)` - returns list of embeddings

7. Factory functions:
   - `create_mock_gcs_client(blobs: List[Dict])` - Pre-configured client with documents
   - `create_mock_faiss_service(vectors: int, documents: List[Dict])` - Configured service
   - `create_mock_rag_corpus_response(results: List[Dict])` - For Vertex AI RAG

8. Helper generators:
   - `generate_mock_embedding(dim=768)` - Random embedding vector
   - `generate_mock_search_results(count: int)` - Sample search results

Include docstrings and usage examples matching existing fixture style.
  </action>
  <verify>
```bash
python -c "from tests.fixtures.gcs_fixtures import MockGCSClient, MockFAISSIndex, create_mock_faiss_service; print('GCS/FAISS fixtures import OK')"
```
  </verify>
  <done>GCS and FAISS mock infrastructure exists and is importable with all documented classes and functions</done>
</task>

<task type="auto">
  <name>Task 2: Create RAG tool tests</name>
  <files>tests/test_rag_tool.py</files>
  <action>
Create comprehensive tests for `src/tools/rag_tool.py` using mocked Vertex AI.

**Test classes to implement:**

1. **TestRAGToolInit**:
   - `test_init_with_config` - Tool initializes with valid ClientConfig
   - `test_init_missing_corpus_id` - Warns when corpus_id not configured
   - `test_init_vertex_ai_error` - Handles aiplatform.init failure gracefully
   - `test_corpus_id_from_config` - Uses config.corpus_id correctly

2. **TestSearchKnowledgeBase**:
   - `test_search_returns_formatted_results` - Returns formatted string with results
   - `test_search_no_corpus_returns_message` - Returns "not configured" when no corpus
   - `test_search_no_results` - Returns "no relevant information" message
   - `test_search_with_top_k` - Respects top_k parameter
   - `test_search_with_agent_type_helpdesk` - Works with helpdesk agent type
   - `test_search_with_agent_type_inbound` - Works with inbound agent type
   - `test_search_handles_error` - Returns error message on exception
   - `test_search_logs_query` - Logs search query at INFO level

3. **TestFormatResults**:
   - `test_format_results_multiple_documents` - Formats multiple results
   - `test_format_results_with_source_uri` - Includes source URI from context
   - `test_format_results_missing_text` - Handles contexts without text attribute
   - `test_format_results_empty_list` - Handles empty contexts

4. **TestSearchWithFilters**:
   - `test_search_with_filters_basic` - Returns list of dicts
   - `test_search_with_filters_empty_results` - Returns empty list
   - `test_search_with_filters_error` - Returns empty list on error
   - `test_search_respects_top_k` - Limits results to top_k

5. **TestScoredResult**:
   - `test_scored_result_dataclass` - ScoredResult has all fields
   - `test_scored_result_defaults` - chunk_hash defaults to empty string

**Mocking strategy:**
- Patch `google.cloud.aiplatform.init` at `src.tools.rag_tool.aiplatform.init`
- Patch `vertexai.preview.rag.retrieval_query` at `src.tools.rag_tool.rag.retrieval_query`
- Create mock RagResource and response objects
- Use `@pytest.fixture` for mock config with corpus_id

Target: 20+ tests covering all major code paths, achieving 50%+ coverage on rag_tool.py
  </action>
  <verify>
```bash
cd "C:\Users\jerry\Documents\multitenant-ai-platform-lite" && python -m pytest tests/test_rag_tool.py -v --tb=short 2>&1 | head -60
```
  </verify>
  <done>All RAG tool tests pass; coverage of rag_tool.py reaches 50%+</done>
</task>

<task type="auto">
  <name>Task 3: Create FAISS helpdesk service tests</name>
  <files>tests/test_faiss_service.py</files>
  <action>
Create comprehensive tests for `src/services/faiss_helpdesk_service.py` using GCS/FAISS mocks.

**Test classes to implement:**

1. **TestFAISSServiceInit**:
   - `test_singleton_pattern` - Returns same instance on multiple calls
   - `test_init_not_initialized_by_default` - _initialized is False initially
   - `test_cache_directory_created` - CACHE_DIR exists after init

2. **TestFAISSServiceInitialize**:
   - `test_initialize_downloads_from_gcs` - Downloads index and metadata
   - `test_initialize_loads_faiss_index` - Loads FAISS index from file
   - `test_initialize_loads_docstore` - Loads document metadata
   - `test_initialize_gcs_failure` - Returns False when GCS unavailable
   - `test_initialize_missing_index_file` - Returns False when index missing
   - `test_initialize_embeddings_model` - Loads sentence transformer
   - `test_initialize_cached_files_used` - Uses cached files if recent

3. **TestFAISSServiceSearch**:
   - `test_search_returns_results` - Returns list of result dicts
   - `test_search_uninitialized_returns_empty` - Returns empty if not initialized
   - `test_search_with_top_k` - Respects top_k parameter
   - `test_search_result_has_content` - Results have content field
   - `test_search_result_has_score` - Results have score field
   - `test_search_result_has_source` - Results have source field
   - `test_search_handles_invalid_index` - Handles idx=-1 gracefully
   - `test_search_logs_query` - Logs search operation

4. **TestSearchWithContext**:
   - `test_search_with_context_basic` - Returns filtered results
   - `test_search_with_context_min_score` - Filters by min_score
   - `test_search_with_context_uses_mmr` - Applies MMR when requested
   - `test_search_with_context_minimum_three` - Returns at least 3 if available

5. **TestSearchWithMMR**:
   - `test_mmr_returns_diverse_results` - Returns diverse documents
   - `test_mmr_fallback_to_regular` - Falls back to search on error
   - `test_mmr_respects_lambda` - lambda_mult affects selection
   - `test_mmr_first_selection_most_relevant` - First result is most relevant

6. **TestGetDocument**:
   - `test_get_document_langchain_format` - Handles InMemoryDocstore
   - `test_get_document_dict_format` - Handles dict docstore
   - `test_get_document_list_format` - Handles list docstore
   - `test_get_document_not_found` - Returns None for missing doc

7. **TestGetStatus**:
   - `test_get_status_initialized` - Returns initialized=True when ready
   - `test_get_status_not_initialized` - Returns initialized=False before init
   - `test_get_status_has_error` - Includes error message if present
   - `test_get_status_vector_count` - Includes vector count from index

8. **TestHelperFunctions**:
   - `test_get_faiss_helpdesk_service_singleton` - Returns singleton instance
   - `test_reset_faiss_service` - Resets singleton to None
   - `test_reset_faiss_service_clears_cache` - Optionally clears cache dir
   - `test_initialize_faiss_service_async` - Async wrapper calls initialize

**Mocking strategy:**
- Patch `google.cloud.storage.Client` at `src.services.faiss_helpdesk_service.storage.Client`
- Patch `faiss.read_index` at `src.services.faiss_helpdesk_service.faiss.read_index`
- Patch `sentence_transformers.SentenceTransformer`
- Use tmp_path fixture for cache directory isolation
- Reset singleton between tests via `FAISSHelpdeskService._instance = None`

Target: 30+ tests covering all major code paths, achieving 50%+ coverage on faiss_helpdesk_service.py
  </action>
  <verify>
```bash
cd "C:\Users\jerry\Documents\multitenant-ai-platform-lite" && python -m pytest tests/test_faiss_service.py -v --tb=short 2>&1 | head -80
```
  </verify>
  <done>All FAISS service tests pass; coverage of faiss_helpdesk_service.py reaches 50%+</done>
</task>

<task type="auto">
  <name>Task 4: Create file upload multipart tests</name>
  <files>tests/test_file_upload.py</files>
  <action>
Create tests for file upload endpoints with multipart form data handling in admin knowledge routes.

**Test classes to implement:**

1. **TestFileUploadAuth**:
   - `test_upload_requires_admin_token` - Returns 401/403 without valid admin token
   - `test_upload_with_valid_token` - Accepts request with valid admin token

2. **TestFileUploadEndpoint**:
   - `test_upload_document_multipart` - Uploads file via multipart form data
   - `test_upload_document_validates_file_type` - Rejects non-text/non-pdf files
   - `test_upload_document_validates_file_size` - Handles large files appropriately
   - `test_upload_document_empty_file` - Handles empty file gracefully
   - `test_upload_document_missing_file` - Returns error when file field missing

3. **TestMultipartParsing**:
   - `test_parse_multipart_form_data` - Parses multipart/form-data correctly
   - `test_handle_multiple_files` - Handles multiple file uploads if supported
   - `test_content_type_detection` - Detects content type from file header
   - `test_filename_extraction` - Extracts original filename correctly

4. **TestUploadToGCS**:
   - `test_upload_saves_to_gcs` - Verifies GCS upload is called with correct params
   - `test_upload_gcs_failure` - Handles GCS upload failure gracefully
   - `test_upload_returns_document_id` - Returns created document ID

**Mocking strategy:**
- Mock GCS client using fixtures from gcs_fixtures.py
- Use TestClient with `files` parameter for multipart uploads:
  ```python
  files = {"file": ("test.txt", b"content", "text/plain")}
  response = client.post("/api/v1/admin/knowledge/documents", files=files)
  ```
- Mock admin token validation via X-Admin-Token header

Target: 15+ tests covering file upload handling paths
  </action>
  <verify>
```bash
cd "C:\Users\jerry\Documents\multitenant-ai-platform-lite" && python -m pytest tests/test_file_upload.py -v --tb=short 2>&1 | head -40
```
  </verify>
  <done>All file upload multipart tests pass; upload handling code paths covered</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `python -c "from tests.fixtures.gcs_fixtures import *"` imports without error
2. `pytest tests/test_rag_tool.py tests/test_faiss_service.py tests/test_file_upload.py -v` shows 65+ tests passing
3. Coverage report shows RAG/FAISS modules at 50%+
4. File upload multipart handling tests pass
</verification>

<success_criteria>
- GCS/FAISS mock fixtures module created with documented classes
- RAG tool tests achieve 50%+ coverage
- FAISS service tests achieve 50%+ coverage
- File upload multipart tests cover upload handling paths
- All tests pass without making real GCS or Vertex AI calls
- Mock infrastructure is reusable for other RAG-related tests
</success_criteria>

<output>
After completion, create `.planning/phases/15-coverage-finalization/15-01-SUMMARY.md`
</output>
