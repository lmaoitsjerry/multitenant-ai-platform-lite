---
phase: 17-error-handling-resilience
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/rag_response_service.py
  - src/services/faiss_helpdesk_service.py
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "OpenAI API calls retry up to 3 times with exponential backoff"
    - "Circuit breaker opens after 5 consecutive failures"
    - "GCS downloads retry on transient failures"
    - "Helpdesk returns fallback response when OpenAI unavailable"
  artifacts:
    - path: "src/services/rag_response_service.py"
      provides: "Circuit breaker and retry logic for OpenAI"
      contains: "@retry"
    - path: "src/services/faiss_helpdesk_service.py"
      provides: "Retry logic for GCS downloads"
      contains: "@retry"
  key_links:
    - from: "src/services/rag_response_service.py"
      to: "OpenAI API"
      via: "tenacity retry decorator"
      pattern: "@retry.*exponential"
    - from: "src/services/faiss_helpdesk_service.py"
      to: "GCS client"
      via: "tenacity retry decorator"
      pattern: "@retry.*download_from_gcs"
---

<objective>
Add circuit breaker and retry logic to external service calls (OpenAI API, GCS).

Purpose: External services fail transiently. Without retry logic, single network blips cause user-facing errors. Without circuit breakers, cascading failures overload systems during outages.

Output: rag_response_service.py with OpenAI circuit breaker + retry, faiss_helpdesk_service.py with GCS retry logic.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/PRODUCTION-AUDIT.md
@src/services/rag_response_service.py
@src/services/faiss_helpdesk_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tenacity dependency</name>
  <files>requirements.txt</files>
  <action>
Add tenacity library to requirements.txt:
```
tenacity>=8.2.0
```

Tenacity is the standard Python library for retry logic with:
- Exponential backoff
- Configurable stop conditions
- Exception filtering
- Retry statistics
  </action>
  <verify>Run `pip install tenacity>=8.2.0` and `python -c "from tenacity import retry; print('OK')"`</verify>
  <done>tenacity is installed and importable</done>
</task>

<task type="auto">
  <name>Task 2: Add circuit breaker and retry to OpenAI API calls</name>
  <files>src/services/rag_response_service.py</files>
  <action>
Add circuit breaker and retry logic to the RAGResponseService._call_llm method.

1. Add imports at top:
```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import threading
import time
```

2. Add circuit breaker class after imports:
```python
class CircuitBreaker:
    """Simple circuit breaker for external service calls"""

    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failures = 0
        self.last_failure_time = 0
        self.state = "closed"  # closed, open, half-open
        self._lock = threading.Lock()

    def record_success(self):
        with self._lock:
            self.failures = 0
            self.state = "closed"

    def record_failure(self):
        with self._lock:
            self.failures += 1
            self.last_failure_time = time.time()
            if self.failures >= self.failure_threshold:
                self.state = "open"
                logger.warning(f"Circuit breaker OPEN after {self.failures} failures")

    def can_execute(self) -> bool:
        with self._lock:
            if self.state == "closed":
                return True
            if self.state == "open":
                if time.time() - self.last_failure_time >= self.recovery_timeout:
                    self.state = "half-open"
                    logger.info("Circuit breaker HALF-OPEN, allowing test request")
                    return True
                return False
            return True  # half-open allows requests

    def get_status(self) -> dict:
        return {
            "state": self.state,
            "failures": self.failures,
            "threshold": self.failure_threshold
        }

# Global circuit breaker for OpenAI
_openai_circuit_breaker = CircuitBreaker(failure_threshold=5, recovery_timeout=60)
```

3. Add retry decorator function (after circuit breaker class):
```python
def _is_retryable_openai_error(exception: Exception) -> bool:
    """Determine if an OpenAI error is retryable"""
    import openai
    retryable_types = (
        openai.RateLimitError,
        openai.APIConnectionError,
        openai.APITimeoutError,
        openai.InternalServerError,
    )
    return isinstance(exception, retryable_types)
```

4. Replace the _call_llm method with retry logic:
```python
def _call_llm(self, question: str, context: str, query_type: str = "general") -> str:
    """Call GPT-4o-mini to synthesize response with retry and circuit breaker"""
    global _openai_circuit_breaker

    # Check circuit breaker
    if not _openai_circuit_breaker.can_execute():
        logger.warning("Circuit breaker OPEN - returning fallback response")
        raise Exception("OpenAI circuit breaker open")

    try:
        response = self._call_llm_with_retry(question, context, query_type)
        _openai_circuit_breaker.record_success()
        return response
    except Exception as e:
        _openai_circuit_breaker.record_failure()
        raise

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type(Exception),
    before_sleep=lambda retry_state: logger.warning(
        f"OpenAI call failed, retrying in {retry_state.next_action.sleep} seconds..."
    )
)
def _call_llm_with_retry(self, question: str, context: str, query_type: str = "general") -> str:
    """Internal method with retry decorator"""
    import openai

    # Build system prompt with query-specific guidance
    query_guidance = QUERY_TYPE_PROMPTS.get(query_type, QUERY_TYPE_PROMPTS["general"])
    full_system_prompt = SYSTEM_PROMPT + "\n" + query_guidance

    user_prompt = f"""Question: {question}

Context from knowledge base:
{context}

Provide a helpful, natural response using the information above. If the context doesn't contain relevant information, honestly acknowledge that."""

    try:
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": full_system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.6,
            max_tokens=500,
            timeout=15.0
        )
        return response.choices[0].message.content
    except openai.RateLimitError as e:
        logger.warning(f"OpenAI rate limit hit: {e}")
        raise
    except openai.APIConnectionError as e:
        logger.warning(f"OpenAI connection error: {e}")
        raise
    except openai.APITimeoutError as e:
        logger.warning(f"OpenAI timeout: {e}")
        raise
    except Exception as e:
        logger.error(f"OpenAI API error: {e}")
        raise
```

5. Update get_status method to include circuit breaker status:
```python
def get_status(self) -> Dict[str, Any]:
    """Get service status for health checks"""
    return {
        "api_key_configured": bool(self.openai_api_key),
        "api_key_valid": self._api_status.get("valid", False),
        "api_status": self._api_status,
        "synthesis_available": self.client is not None,
        "mode": "llm" if self.client else "fallback",
        "circuit_breaker": _openai_circuit_breaker.get_status()
    }
```
  </action>
  <verify>
Run tests and verify the service still works:
```bash
python -c "
from src.services.rag_response_service import RAGResponseService, _openai_circuit_breaker
svc = RAGResponseService()
status = svc.get_status()
print('Circuit breaker status:', status.get('circuit_breaker'))
assert 'circuit_breaker' in status
print('OK')
"
```
  </verify>
  <done>OpenAI API calls have retry logic with exponential backoff and circuit breaker protection</done>
</task>

<task type="auto">
  <name>Task 3: Add retry logic to GCS downloads</name>
  <files>src/services/faiss_helpdesk_service.py</files>
  <action>
Add retry logic to the GCS download method in FAISSHelpdeskService.

1. Add tenacity import at top (after existing imports):
```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
```

2. Add retry-wrapped version of _download_from_gcs method. Replace the existing method with:
```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((IOError, ConnectionError, TimeoutError)),
    before_sleep=lambda retry_state: logger.warning(
        f"GCS download failed, retrying in {retry_state.next_action.sleep} seconds..."
    )
)
def _download_blob(self, blob, local_path: Path) -> bool:
    """Download a blob with retry logic"""
    blob.download_to_filename(str(local_path))
    return True

def _download_from_gcs(self, blob_name: str, local_path: Path) -> bool:
    """Download a file from GCS if not already cached or if stale"""
    try:
        client = self._get_gcs_client()
        if not client:
            return False

        bucket = client.bucket(GCS_BUCKET_NAME)
        blob = bucket.blob(blob_name)

        # Check if blob exists
        if not blob.exists():
            logger.error(f"Blob {blob_name} not found in bucket {GCS_BUCKET_NAME}")
            return False

        # Check if local file exists and is recent (within 24 hours)
        if local_path.exists():
            import time
            file_age = time.time() - local_path.stat().st_mtime
            if file_age < 86400:  # 24 hours
                logger.info(f"Using cached {blob_name} (age: {file_age/3600:.1f} hours)")
                return True

        # Download file with retry
        logger.info(f"Downloading {blob_name} from GCS bucket {GCS_BUCKET_NAME}...")
        try:
            self._download_blob(blob, local_path)
            logger.info(f"Downloaded {blob_name} ({local_path.stat().st_size / 1024 / 1024:.1f} MB)")
            return True
        except Exception as e:
            logger.error(f"Failed to download {blob_name} after retries: {e}")
            # Try to use cached version if available
            if local_path.exists():
                logger.warning(f"Using stale cached {blob_name} due to download failure")
                return True
            return False

    except Exception as e:
        logger.error(f"Failed to download {blob_name} from GCS: {e}")
        return False
```

This adds:
- Retry decorator on the actual download operation
- Exponential backoff (2s, 4s, 8s)
- Fallback to stale cache if fresh download fails
- Proper logging of retry attempts
  </action>
  <verify>
```bash
python -c "
from src.services.faiss_helpdesk_service import FAISSHelpdeskService
# Just verify imports work
print('FAISSHelpdeskService imports OK')
"
```
  </verify>
  <done>GCS downloads retry on transient failures with exponential backoff and fallback to cached index</done>
</task>

</tasks>

<verification>
1. Run existing tests to ensure no regressions:
   ```bash
   pytest tests/test_faiss_service.py tests/test_rag_tool.py -v
   ```

2. Verify imports work:
   ```bash
   python -c "
   from src.services.rag_response_service import RAGResponseService, _openai_circuit_breaker
   from src.services.faiss_helpdesk_service import FAISSHelpdeskService
   print('All imports OK')
   "
   ```

3. Check circuit breaker status endpoint:
   ```bash
   python -c "
   from src.services.rag_response_service import RAGResponseService
   svc = RAGResponseService()
   status = svc.get_status()
   assert 'circuit_breaker' in status
   assert status['circuit_breaker']['state'] == 'closed'
   print('Circuit breaker configured correctly')
   "
   ```
</verification>

<success_criteria>
- tenacity library added to requirements.txt
- RAGResponseService._call_llm has retry decorator (3 attempts, exponential backoff)
- CircuitBreaker class implemented with 5-failure threshold
- FAISSHelpdeskService._download_from_gcs has retry logic
- Existing tests pass (pytest tests/test_faiss_service.py tests/test_rag_tool.py)
- Service health check includes circuit breaker status
</success_criteria>

<output>
After completion, create `.planning/phases/17-error-handling-resilience/17-01-SUMMARY.md`
</output>
