---
phase: 02-tenant-lookup-email-parsing
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/agents/universal_email_parser.py
  - src/agents/llm_email_parser.py
autonomous: true

must_haves:
  truths:
    - "Email parser extracts destination from email body"
    - "Email parser extracts travel dates (check_in, check_out)"
    - "Email parser extracts traveler counts (adults, children)"
    - "Email parser extracts budget when mentioned"
    - "LLM parser failure falls back to rule-based parser"
    - "Parser handles malformed emails gracefully"
  artifacts:
    - path: "src/agents/llm_email_parser.py"
      provides: "LLM-powered email parsing"
      exports: ["LLMEmailParser"]
    - path: "src/agents/universal_email_parser.py"
      provides: "Rule-based email parsing (fallback)"
      contains: "class UniversalEmailParser"
  key_links:
    - from: "src/webhooks/email_webhook.py"
      to: "src/agents/universal_email_parser.py"
      via: "parser = UniversalEmailParser(config)"
      pattern: "UniversalEmailParser\\(config\\)"
    - from: "LLMEmailParser.parse()"
      to: "UniversalEmailParser.parse()"
      via: "fallback on LLM failure"
      pattern: "except.*UniversalEmailParser"
---

<objective>
Implement LLM-powered email parser with rule-based fallback for robust trip detail extraction.

Purpose: Extract destination, dates, travelers, and budget from customer emails using OpenAI GPT-4o-mini with automatic fallback to existing regex-based parser on LLM failures.

Output: New LLMEmailParser class that enhances parsing accuracy while maintaining reliability through fallback.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/agents/universal_email_parser.py
@src/webhooks/email_webhook.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLM-powered email parser</name>
  <files>src/agents/llm_email_parser.py</files>
  <action>
Create a new LLM-powered email parser that uses OpenAI GPT-4o-mini for intelligent extraction.

```python
"""
LLM Email Parser - Uses OpenAI for intelligent email parsing

Falls back to UniversalEmailParser (rule-based) on any failure.
Uses GPT-4o-mini for cost efficiency (~$0.15/1M input tokens).
"""

import os
import json
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime

from config.loader import ClientConfig

logger = logging.getLogger(__name__)


class LLMEmailParser:
    """LLM-powered email parser with rule-based fallback"""

    def __init__(self, config: ClientConfig):
        self.config = config
        self.destinations = config.destination_names
        self.openai_api_key = os.getenv('OPENAI_API_KEY')

        # Initialize rule-based parser as fallback
        from src.agents.universal_email_parser import UniversalEmailParser
        self.fallback_parser = UniversalEmailParser(config)

        logger.info(f"LLM parser initialized with {len(self.destinations)} destinations")

    def parse(self, email_body: str, subject: str = "") -> Dict[str, Any]:
        """
        Parse email using LLM with fallback to rule-based.

        Returns dict with:
        - destination: str
        - check_in: str (YYYY-MM-DD) or None
        - check_out: str (YYYY-MM-DD) or None
        - adults: int
        - children: int
        - children_ages: List[int]
        - budget: int or None
        - budget_is_per_person: bool
        - name: str
        - email: str
        - phone: str or None
        - is_travel_inquiry: bool
        - parse_method: str ('llm' or 'fallback')
        """
        full_text = f"Subject: {subject}\n\n{email_body}"

        # Try LLM parsing first
        if self.openai_api_key:
            try:
                result = self._parse_with_llm(full_text)
                if result and result.get('destination'):
                    result['parse_method'] = 'llm'
                    logger.info(f"LLM parsed: {result.get('destination')} | "
                               f"{result.get('adults', 2)}A+{result.get('children', 0)}C")
                    return result
            except Exception as e:
                logger.warning(f"LLM parsing failed, using fallback: {e}")
        else:
            logger.info("No OPENAI_API_KEY, using fallback parser")

        # Fallback to rule-based parser
        result = self.fallback_parser.parse(email_body, subject)
        result['parse_method'] = 'fallback'
        return result

    def _parse_with_llm(self, full_text: str) -> Optional[Dict[str, Any]]:
        """Parse email using OpenAI GPT-4o-mini"""
        import openai

        # Build destination list for context
        dest_list = ', '.join(self.destinations[:20])  # Limit for prompt size

        system_prompt = f"""You are an email parser for a travel agency. Extract travel inquiry details from customer emails.

Available destinations: {dest_list}

Return a JSON object with these fields (use null for unknown):
- destination: string (must match one of the available destinations, or closest match)
- check_in: string (YYYY-MM-DD format) or null
- check_out: string (YYYY-MM-DD format) or null
- adults: integer (default 2 if not specified)
- children: integer (default 0 if not specified)
- children_ages: array of integers (empty if not specified)
- budget: integer (total budget in local currency, e.g., ZAR) or null
- budget_is_per_person: boolean (true if budget was specified per person)
- name: string (customer name) or "Valued Customer"
- email: string (customer email) or null
- phone: string (customer phone) or null
- is_travel_inquiry: boolean (true if this is about travel/vacation)
- special_requests: string (any special requirements mentioned) or null

Rules:
1. If dates mention a month without year, assume next occurrence of that month
2. If nights are mentioned without specific dates, set check_out = check_in + nights
3. Convert "2 pax" to adults=2, "2 adults 1 child" to adults=2, children=1
4. Budget might be in format "R50000" (ZAR) or "50k" - convert to integer
5. Match destination to closest available option (e.g., "Zanzibar" matches "Zanzibar")

Return ONLY valid JSON, no markdown or explanation."""

        try:
            client = openai.OpenAI(api_key=self.openai_api_key)

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": full_text[:4000]}  # Limit input size
                ],
                temperature=0.1,  # Low temperature for consistent extraction
                max_tokens=500,
                response_format={"type": "json_object"}
            )

            result_text = response.choices[0].message.content
            result = json.loads(result_text)

            # Validate and normalize result
            return self._normalize_llm_result(result)

        except json.JSONDecodeError as e:
            logger.error(f"LLM returned invalid JSON: {e}")
            return None
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return None

    def _normalize_llm_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize LLM output to expected format"""
        normalized = {
            'destination': result.get('destination') or self.destinations[0] if self.destinations else 'Unknown',
            'check_in': result.get('check_in'),
            'check_out': result.get('check_out'),
            'adults': int(result.get('adults', 2)),
            'children': int(result.get('children', 0)),
            'children_ages': result.get('children_ages', []),
            'budget': None,
            'budget_is_per_person': bool(result.get('budget_is_per_person', False)),
            'name': result.get('name', 'Valued Customer'),
            'email': result.get('email'),
            'phone': result.get('phone'),
            'is_travel_inquiry': bool(result.get('is_travel_inquiry', True)),
            'special_requests': result.get('special_requests')
        }

        # Handle budget conversion
        budget = result.get('budget')
        if budget is not None:
            try:
                if isinstance(budget, str):
                    budget = budget.replace('R', '').replace(',', '').replace('k', '000')
                normalized['budget'] = int(float(budget))
            except (ValueError, TypeError):
                normalized['budget'] = None

        # Map destination to closest match if not exact
        if normalized['destination'] not in self.destinations:
            normalized['destination'] = self._find_closest_destination(normalized['destination'])

        # Also set total_budget for compatibility
        if normalized['budget']:
            normalized['total_budget'] = normalized['budget']

        return normalized

    def _find_closest_destination(self, destination: str) -> str:
        """Find closest matching destination from available list"""
        if not destination or not self.destinations:
            return self.destinations[0] if self.destinations else 'Unknown'

        from difflib import SequenceMatcher

        dest_lower = destination.lower()
        best_match = self.destinations[0]
        best_ratio = 0.0

        for d in self.destinations:
            ratio = SequenceMatcher(None, dest_lower, d.lower()).ratio()
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = d

        # Only use match if reasonably confident
        if best_ratio >= 0.6:
            return best_match

        return self.destinations[0] if self.destinations else 'Unknown'
```

Key design decisions:
- Uses GPT-4o-mini (cost-efficient, fast)
- JSON mode for structured output
- Low temperature (0.1) for consistent extraction
- Includes destination list in prompt for better matching
- Falls back to UniversalEmailParser on ANY failure
- Logs parse method for debugging
  </action>
  <verify>
File exists: `ls src/agents/llm_email_parser.py`
Contains LLMEmailParser class: `grep "class LLMEmailParser" src/agents/llm_email_parser.py`
Contains fallback logic: `grep "fallback_parser" src/agents/llm_email_parser.py`
  </verify>
  <done>
New LLMEmailParser class created with:
- OpenAI GPT-4o-mini integration
- JSON structured output
- Automatic fallback to UniversalEmailParser
- Destination matching against config
- Budget and date normalization
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate LLM parser into email webhook</name>
  <files>src/webhooks/email_webhook.py</files>
  <action>
Modify `process_inbound_email()` in email_webhook.py to use LLMEmailParser as primary with UniversalEmailParser as fallback.

Find this section (around line 500-515):

```python
# STEP 8: Email parser import
try:
    from src.agents.universal_email_parser import UniversalEmailParser
    from src.agents.quote_agent import QuoteAgent
    diagnostic_log(diagnostic_id, 8, "Email parser imported successfully")
except ImportError as e:
    ...

# STEP 9: Email parsed
parser = UniversalEmailParser(config)
parsed_data = parser.parse(email.body_text, email.subject)
```

Replace with:

```python
# STEP 8: Email parser import
try:
    from src.agents.llm_email_parser import LLMEmailParser
    from src.agents.universal_email_parser import UniversalEmailParser
    from src.agents.quote_agent import QuoteAgent
    diagnostic_log(diagnostic_id, 8, "Email parsers imported successfully", {
        'llm_parser': 'LLMEmailParser',
        'fallback_parser': 'UniversalEmailParser'
    })
except ImportError as e:
    diagnostic_log(diagnostic_id, 8, f"FAILED: Import error", {
        'error': str(e),
        'module': 'LLMEmailParser or QuoteAgent'
    })
    raise

# STEP 9: Email parsed
# Try LLM parser first (has built-in fallback to rule-based)
parser = LLMEmailParser(config)
parsed_data = parser.parse(email.body_text, email.subject)
```

Also update the STEP 9 logging to include parse_method:

```python
diagnostic_log(diagnostic_id, 9, "Email parsed", {
    'destination': parsed_data.get('destination'),
    'is_travel_inquiry': parsed_data.get('is_travel_inquiry'),
    'parse_method': parsed_data.get('parse_method', 'unknown'),  # ADD THIS
    'customer_name': parsed_data.get('name'),
    'customer_email': parsed_data.get('email'),
    'adults': parsed_data.get('adults'),
    'children': parsed_data.get('children'),
    'check_in': parsed_data.get('check_in'),
    'check_out': parsed_data.get('check_out'),
    'budget': parsed_data.get('budget')
})
```

This change ensures:
1. LLM parser is tried first for better accuracy
2. If LLM fails, fallback happens inside LLMEmailParser
3. Diagnostic logging shows which parser was used
4. No change to QuoteAgent or downstream flow
  </action>
  <verify>
Grep for LLMEmailParser import: `grep "from src.agents.llm_email_parser" src/webhooks/email_webhook.py`
Grep for parse_method logging: `grep "parse_method" src/webhooks/email_webhook.py`
  </verify>
  <done>
Email webhook now uses LLMEmailParser as primary parser.
Diagnostic logging includes parse_method field.
Fallback to UniversalEmailParser on LLM failure.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add edge case handling and tests</name>
  <files>src/agents/llm_email_parser.py, tests/test_email_parser.py</files>
  <action>
1. Add edge case handling to LLMEmailParser:

In `_parse_with_llm()`, add timeout handling:

```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[...],
    temperature=0.1,
    max_tokens=500,
    response_format={"type": "json_object"},
    timeout=10.0  # 10 second timeout
)
```

2. Create test file `tests/test_email_parser.py`:

```python
"""
Tests for email parsing - both LLM and rule-based
"""
import pytest
from unittest.mock import patch, MagicMock
import json


class MockConfig:
    """Mock ClientConfig for testing"""
    def __init__(self):
        self.client_id = 'test'
        self.destination_names = ['Zanzibar', 'Mauritius', 'Maldives', 'Seychelles']


class TestLLMEmailParser:
    """Test LLM email parser"""

    def test_parse_with_no_api_key_uses_fallback(self):
        """Should use fallback when no API key"""
        with patch.dict('os.environ', {'OPENAI_API_KEY': ''}):
            from src.agents.llm_email_parser import LLMEmailParser
            parser = LLMEmailParser(MockConfig())

            result = parser.parse("I want to go to Zanzibar", "Travel inquiry")

            assert result['parse_method'] == 'fallback'
            assert result['destination'] == 'Zanzibar'

    @patch('openai.OpenAI')
    def test_parse_with_llm_success(self, mock_openai):
        """Should parse successfully with LLM"""
        # Mock OpenAI response
        mock_response = MagicMock()
        mock_response.choices = [MagicMock()]
        mock_response.choices[0].message.content = json.dumps({
            'destination': 'Zanzibar',
            'check_in': '2025-06-15',
            'check_out': '2025-06-22',
            'adults': 2,
            'children': 1,
            'children_ages': [5],
            'budget': 50000,
            'name': 'John Doe',
            'email': 'john@example.com',
            'is_travel_inquiry': True
        })
        mock_openai.return_value.chat.completions.create.return_value = mock_response

        with patch.dict('os.environ', {'OPENAI_API_KEY': 'test-key'}):
            from src.agents.llm_email_parser import LLMEmailParser
            parser = LLMEmailParser(MockConfig())

            result = parser.parse("I want to go to Zanzibar in June", "Travel")

            assert result['parse_method'] == 'llm'
            assert result['destination'] == 'Zanzibar'
            assert result['adults'] == 2
            assert result['children'] == 1

    @patch('openai.OpenAI')
    def test_parse_llm_failure_uses_fallback(self, mock_openai):
        """Should use fallback when LLM fails"""
        mock_openai.return_value.chat.completions.create.side_effect = Exception("API Error")

        with patch.dict('os.environ', {'OPENAI_API_KEY': 'test-key'}):
            from src.agents.llm_email_parser import LLMEmailParser
            parser = LLMEmailParser(MockConfig())

            result = parser.parse("I want to go to Mauritius", "Travel inquiry")

            assert result['parse_method'] == 'fallback'
            # Fallback should still extract destination
            assert result['destination'] in ['Mauritius', 'Zanzibar']  # May match or default

    def test_normalize_budget_formats(self):
        """Should normalize various budget formats"""
        with patch.dict('os.environ', {'OPENAI_API_KEY': ''}):
            from src.agents.llm_email_parser import LLMEmailParser
            parser = LLMEmailParser(MockConfig())

            # Test budget normalization
            result1 = parser._normalize_llm_result({'budget': 'R50000'})
            assert result1['budget'] == 50000

            result2 = parser._normalize_llm_result({'budget': '50k'})
            assert result2['budget'] == 50000

            result3 = parser._normalize_llm_result({'budget': 50000})
            assert result3['budget'] == 50000


class TestUniversalEmailParser:
    """Test rule-based fallback parser"""

    def test_extract_destination(self):
        """Should extract destination from text"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        result = parser.parse("I want to visit Zanzibar in December", "Quote request")
        assert result['destination'] == 'Zanzibar'

    def test_extract_travelers(self):
        """Should extract adult and child counts"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        result = parser.parse("Trip for 2 adults and 3 children", "Family holiday")
        assert result['adults'] == 2
        assert result['children'] == 3

    def test_default_values_for_malformed_email(self):
        """Should return defaults for malformed emails"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        result = parser.parse("", "")  # Empty email
        assert result['adults'] == 2  # Default
        assert result['children'] == 0  # Default
        assert result['destination'] in parser.DESTINATIONS  # Some destination


class TestEdgeCases:
    """Test edge cases and error handling"""

    def test_empty_body_and_subject(self):
        """Should handle empty email gracefully"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        result = parser.parse("", "")
        assert result is not None
        assert 'destination' in result
        assert 'adults' in result

    def test_very_long_email(self):
        """Should handle very long emails"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        long_body = "I want to go to Zanzibar. " * 1000
        result = parser.parse(long_body, "Quote")
        assert result['destination'] == 'Zanzibar'

    def test_special_characters_in_email(self):
        """Should handle special characters"""
        from src.agents.universal_email_parser import UniversalEmailParser
        parser = UniversalEmailParser(MockConfig())

        result = parser.parse(
            "Hello! I'd like to visit Zanzibar... budget ~R50,000???",
            "RE: FW: Quote"
        )
        assert result['destination'] == 'Zanzibar'
```

Run tests with: `pytest tests/test_email_parser.py -v`
  </action>
  <verify>
Test file exists: `ls tests/test_email_parser.py`
Tests pass: `pytest tests/test_email_parser.py -v`
At least 8 test cases covering LLM and fallback scenarios.
  </verify>
  <done>
Edge case handling added (timeout, empty input).
Comprehensive tests cover:
- LLM parsing success
- Fallback on LLM failure
- Budget normalization
- Traveler extraction
- Empty/malformed email handling
- Long email handling
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **LLM Parser exists:**
   ```bash
   ls src/agents/llm_email_parser.py
   grep "class LLMEmailParser" src/agents/llm_email_parser.py
   ```

2. **Webhook integration:**
   ```bash
   grep "LLMEmailParser" src/webhooks/email_webhook.py
   ```

3. **Tests pass:**
   ```bash
   pytest tests/test_email_parser.py -v
   ```

4. **Functional test (requires OPENAI_API_KEY):**
   ```bash
   python -c "
   from config.loader import ClientConfig
   from src.agents.llm_email_parser import LLMEmailParser

   config = ClientConfig('africastay')
   parser = LLMEmailParser(config)
   result = parser.parse('I want to go to Zanzibar for 7 nights in June. 2 adults and 1 child age 5. Budget around R50000.', 'Quote request')
   print(f'Method: {result.get(\"parse_method\")}')
   print(f'Destination: {result.get(\"destination\")}')
   print(f'Adults: {result.get(\"adults\")}')
   print(f'Children: {result.get(\"children\")}')
   print(f'Budget: {result.get(\"budget\")}')
   "
   ```
</verification>

<success_criteria>
1. LLMEmailParser class exists with OpenAI GPT-4o-mini integration
2. Parser extracts: destination, dates, travelers, budget
3. Automatic fallback to UniversalEmailParser on LLM failure
4. Email webhook uses LLMEmailParser as primary parser
5. Diagnostic logging shows parse_method (llm vs fallback)
6. Tests pass for LLM, fallback, and edge cases
7. No breaking changes to downstream quote generation
</success_criteria>

<output>
After completion, create `.planning/phases/02-tenant-lookup-email-parsing/02-02-SUMMARY.md`
</output>
